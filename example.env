# .env file - DeepSeek Coder Setup
# Copy this to .env and modify as needed

# Security
SECRET_KEY=your-very-secret-key-change-this-in-production-make-it-long-and-random
SECURE_COOKIES=false  # Set to true for HTTPS production

# Admin User Configuration
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123

# Database Configuration
REDIS_URL=redis://redis:6379/0

# AI Model Configuration
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=deepseek-coder-v2:16b

# Model Generation Parameters
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2048
MODEL_TIMEOUT=300

# Rate Limiting
RATE_LIMIT_MESSAGES_PER_MINUTE=10
RATE_LIMIT_LOGIN_ATTEMPTS_PER_MINUTE=5
RATE_LIMIT_API_CALLS_PER_MINUTE=30

# Chat Configuration
CHAT_CACHE_TTL_SECONDS=3600  # 1 hour
CHAT_HISTORY_LIMIT=100
SESSION_LIFETIME_DAYS=7

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_WORKERS=4
DEBUG=false

# Nginx Configuration
NGINX_RATE_LIMIT_GENERAL=60
NGINX_RATE_LIMIT_LOGIN=5
NGINX_RATE_LIMIT_API=30
NGINX_GENERAL_BURST=20
NGINX_API_BURST=10
NGINX_LOGIN_BURST=3
NGINX_PROXY_TIMEOUT=600

# Docker Resource Limits (for docker-compose)
QUART_APP_MEMORY_LIMIT=8G
QUART_APP_MEMORY_RESERVATION=4G
OLLAMA_MEMORY_LIMIT=16G
OLLAMA_MEMORY_RESERVATION=8G
REDIS_MEMORY_LIMIT=2G

# GPU Configuration
NVIDIA_VISIBLE_DEVICES=all
CUDA_MEMORY_FRACTION=0.8

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json