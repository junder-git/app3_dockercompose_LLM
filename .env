# .env file - HIGH PERFORMANCE with PERMANENT RAM/VRAM LOADING
SECRET_KEY=your-very-secret-key-change-this-in-production
SECURE_COOKIES=false
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
REDIS_URL=redis://redis:6379/0

# AI Model Configuration - HIGH PERFORMANCE 7.5GB mode
OLLAMA_HOST=0.0.0.0
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=deepseek-r1:1.5b
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2048               # High performance - longer responses
MODEL_TIMEOUT=120                   # 2 minutes (model is pre-loaded)

# Rate Limiting - GENEROUS LIMITS (10x higher)
RATE_LIMIT_MESSAGES_PER_MINUTE=80   # 10x higher (was 8)
RATE_LIMIT_LOGIN_ATTEMPTS_PER_MINUTE=50
RATE_LIMIT_API_CALLS_PER_MINUTE=250

# Chat Configuration - High performance
CHAT_CACHE_TTL_SECONDS=7200
CHAT_HISTORY_LIMIT=25               # Good context with 7.5GB
SESSION_LIFETIME_DAYS=7

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_WORKERS=1

# Docker Resource Limits - High performance
QUART_APP_MEMORY_LIMIT=1G
QUART_APP_MEMORY_RESERVATION=1G
OLLAMA_MEMORY_LIMIT=16G
OLLAMA_MEMORY_RESERVATION=16G
REDIS_MEMORY_LIMIT=1G

# GPU Configuration - 7.5GB VRAM target (VALID OPTIONS ONLY)
NVIDIA_VISIBLE_DEVICES=0
CUDA_MEMORY_FRACTION=0.95           # Use almost all VRAM
OLLAMA_GPU_LAYERS=12                # Target
OLLAMA_NUM_THREAD=4                 # Fewer CPU threads (more on GPU)

# CRITICAL: Permanent RAM/VRAM Loading Settings
OLLAMA_MLOCK=true                   # Lock model in RAM/VRAM - prevents swapping
OLLAMA_MMAP=false                   # Disable memory mapping - force full RAM loading
OLLAMA_NUMA=false                   # Disable NUMA for single-GPU setups

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# SSE Configuration - High performance
SSE_HEARTBEAT_INTERVAL=30
SSE_MAX_CONNECTIONS=50              # Much higher for better performance
SSE_RETRY_TIMEOUT=5000

# Performance Optimizations - VALID OPTIONS ONLY
OLLAMA_MAIN_GPU=0
OLLAMA_CONTEXT_SIZE=16384           # Large context
OLLAMA_BATCH_SIZE=256               # Large batches
OLLAMA_KEEP_ALIVE=-1                # Permanent loading

# Memory Management - PERMANENT LOADING
OLLAMA_MAX_LOADED_MODELS=1          # Only load one model at a time
OLLAMA_LOAD_TIMEOUT=15m             # Allow time for full loading
OLLAMA_NOPRUNE=true                 # Never unload models automatically

# REMOVED INVALID OPTIONS:
# OLLAMA_FLASH_ATTENTION (not valid)
# OLLAMA_LOW_VRAM (not valid)
# OLLAMA_ROPE_SCALING (not valid)