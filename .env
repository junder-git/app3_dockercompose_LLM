# .env file - Complete Environment-Driven Configuration
# =============================================================================
# DOCKER COMPOSE RESOURCE LIMITS
# =============================================================================
QUART_APP_MEMORY=1G
QUART_APP_CPU=1
OLLAMA_MEMORY=16G
OLLAMA_CPU=4
REDIS_MEMORY=1G
REDIS_CPU=1
NGINX_MEMORY=1G
NGINX_CPU=1

# =============================================================================
# CURRENT MODEL CONFIGURATION (Change these for different models)
# =============================================================================
# For DeepSeek R1 1.5B:
OLLAMA_MODEL=deepseek-r1:1.5b
MODEL_DISPLAY_NAME=DeepSeek R1 1.5B
MODEL_DESCRIPTION=DeepSeek R1 Distilled - Fast reasoning with step-by-step thinking

# For Devstral 24B (uncomment and comment above):
# OLLAMA_MODEL=devstral:24b
# MODEL_DISPLAY_NAME=Devstral 24B
# MODEL_DESCRIPTION=Devstral - Advanced coding and reasoning model

# =============================================================================
# OLLAMA PERFORMANCE PARAMETERS (All configurable)
# =============================================================================
OLLAMA_HOST=0.0.0.0
OLLAMA_URL=http://ollama:11434
OLLAMA_GPU_LAYERS=29                     # 29 for 1.5B, 41 for 24B
OLLAMA_NUM_THREAD=4                      # CPU threads
OLLAMA_CONTEXT_SIZE=8192                # 16384 for 1.5B, 8192 for 24B
OLLAMA_BATCH_SIZE=128                    # 256 for 1.5B, 128 for 24B
OLLAMA_KEEP_ALIVE=-1                     # Permanent loading
OLLAMA_MAX_LOADED_MODELS=1               # Only one model
OLLAMA_LOAD_TIMEOUT=15m                  # 15m for 1.5B, 30m for 24B
OLLAMA_NOPRUNE=1                         # Never unload
OLLAMA_MLOCK=1                           # Lock in RAM/VRAM
OLLAMA_MMAP=0                            # Disable memory mapping
OLLAMA_NUMA=0                            # Disable NUMA
OLLAMA_MAIN_GPU=0                        # Primary GPU

# =============================================================================
# MODELFILE PARAMETERS (All configurable) - FIXED WITH BOOLEAN VALUES
# =============================================================================
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_TOP_K=40
MODEL_REPEAT_PENALTY=1.1
MODEL_MIROSTAT=0
MODEL_MIROSTAT_ETA=0.1
MODEL_MIROSTAT_TAU=5.0
# CRITICAL: Use boolean values for Ollama parameters
MODEL_USE_MMAP=false                     # BOOLEAN: false to disable mmap
MODEL_USE_MLOCK=true                     # BOOLEAN: true to enable mlock
MODEL_STOP_SEQUENCES=["<|endoftext|>", "<|im_end|>", "[DONE]", "<|end|>"]

# =============================================================================
# APPLICATION PERFORMANCE SETTINGS
# =============================================================================
MODEL_MAX_TOKENS=1024                    # 2048 for 1.5B, 1024 for 24B
MODEL_TIMEOUT=300                        # 120 for 1.5B, 180 for 24B
CHAT_HISTORY_LIMIT=25                    # 25 for 1.5B, 15 for 24B
CHAT_CACHE_TTL_SECONDS=7200
RATE_LIMIT_MESSAGES_PER_MINUTE=10
SSE_MAX_CONNECTIONS=25                   # 25

# =============================================================================
# NVIDIA GPU SETTINGS
# =============================================================================
NVIDIA_VISIBLE_DEVICES=0
CUDA_MEMORY_FRACTION=0.95
LOG_LEVEL=INFO
LOG_FORMAT=json

# =============================================================================
# QUART WEB APPLICATION
# =============================================================================
SECRET_KEY=your-very-secret-key-change-this-in-production
SECURE_COOKIES=0
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin
REDIS_URL=redis://redis:6379/0
APP_HOST=0.0.0.0
APP_PORT=8000
APP_WORKERS=1
SESSION_LIFETIME_DAYS=7
SSE_HEARTBEAT_INTERVAL=30
SSE_RETRY_TIMEOUT=5000