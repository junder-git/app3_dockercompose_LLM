# CLEAN .env - Optimized Configuration for Ollama with GGUF Model
# =============================================================================

# üîê JWT CONFIGURATION
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production-min-32-chars

# Domain Configuration
ALLOWED_DOMAINS=localhost,127.0.0.1,ai.junder.uk

# Admin User Configuration
ADMIN_USERNAME=admin1
ADMIN_PASSWORD=admin1
ADMIN_USER_ID=admin

# =============================================================================
# ü§ñ MODEL CONFIGURATION - OLLAMA
# =============================================================================
MODEL_URL=http://ollama:11434
MODEL_NAME=devstral

# =============================================================================
# üéõÔ∏è MODEL PARAMETERS - UPDATED FOR 2048 CONTEXT
# =============================================================================

# Core model parameters
MODEL_TEMPERATURE=0.7                      # Default: 0.7
MODEL_TOP_P=0.9                           # Default: 0.9  
MODEL_TOP_K=40                            # Default: 40
MODEL_MIN_P=0.0                           # Default: 0.0 (disabled)
MODEL_REPEAT_PENALTY=1.1                  # Default: 1.1
MODEL_REPEAT_LAST_N=64                    # Default: 64

# Context and prediction settings
MODEL_NUM_CTX=2048                        # Context window
MODEL_NUM_PREDICT=512                     # Max tokens to generate
MODEL_SEED=0                              # Default: 0                 

# =============================================================================
# üì± APPLICATION SETTINGS
# =============================================================================
RATE_LIMIT_MESSAGES_PER_MINUTE=12        # For 3 concurrent streams
MAX_MESSAGE_LENGTH=8000                   # For longer context

# User Management
MAX_CHATS_PER_USER=3                      # Match parallel processing
MAX_PENDING_USERS=5                       
MIN_USERNAME_LENGTH=3
MAX_USERNAME_LENGTH=12
MIN_PASSWORD_LENGTH=6
MAX_PASSWORD_LENGTH=16

# =============================================================================
# üê≥ DOCKER RESOURCES - OPTIMIZED FOR CPU+GPU HYBRID
# =============================================================================

# Ollama configuration - DEV (32GB VRAM)
OLLAMA_CPU=4.0                            # More CPU for model processing
OLLAMA_MEMORY=22G                         # Large CPU RAM for model layers
OLLAMA_GPU_LAYERS=8                      # Partial GPU offload

# Other services
REDIS_MEMORY=1G
REDIS_CPU=1.0                             
NGINX_MEMORY=512M                           
NGINX_CPU=1.0                             

# =============================================================================
# üì¶ REDIS & NETWORK
# =============================================================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_URL=redis://redis:6379/0

# =============================================================================
# üìù LOGGING
# =============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=json