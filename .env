# .env file - HIGH PERFORMANCE with VALID options only
SECRET_KEY=your-very-secret-key-change-this-in-production
SECURE_COOKIES=false
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
REDIS_URL=redis://redis:6379/0

# AI Model Configuration - HIGH PERFORMANCE 7.5GB mode
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=devstral:24b
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2048               # High performance - longer responses
MODEL_TIMEOUT=120                   # 2 minutes (model is pre-loaded)

# Rate Limiting - GENEROUS LIMITS (10x higher)
RATE_LIMIT_MESSAGES_PER_MINUTE=80   # 10x higher (was 8)
RATE_LIMIT_LOGIN_ATTEMPTS_PER_MINUTE=50
RATE_LIMIT_API_CALLS_PER_MINUTE=250

# Chat Configuration - High performance
CHAT_CACHE_TTL_SECONDS=7200
CHAT_HISTORY_LIMIT=25               # Good context with 7.5GB
SESSION_LIFETIME_DAYS=7

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_WORKERS=2

# Docker Resource Limits - High performance
QUART_APP_MEMORY_LIMIT=3G
QUART_APP_MEMORY_RESERVATION=1G
OLLAMA_MEMORY_LIMIT=24G
OLLAMA_MEMORY_RESERVATION=12G
REDIS_MEMORY_LIMIT=1G

# GPU Configuration - 7.5GB VRAM target (VALID OPTIONS ONLY)
NVIDIA_VISIBLE_DEVICES=0
CUDA_MEMORY_FRACTION=0.95           # Use almost all VRAM
OLLAMA_GPU_LAYERS=22                # Target
OLLAMA_NUM_THREAD=8                 # Fewer CPU threads (more on GPU)

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# SSE Configuration - High performance
SSE_HEARTBEAT_INTERVAL=30
SSE_MAX_CONNECTIONS=50              # Much higher for better performance
SSE_RETRY_TIMEOUT=5000

# Performance Optimizations - VALID OPTIONS ONLY
OLLAMA_MAIN_GPU=0
OLLAMA_CONTEXT_SIZE=16384           # Large context
OLLAMA_BATCH_SIZE=256               # Large batches
OLLAMA_KEEP_ALIVE=-1                # Permanent loading

# REMOVED INVALID OPTIONS:
# OLLAMA_FLASH_ATTENTION (not valid)
# OLLAMA_LOW_VRAM (not valid)
# OLLAMA_ROPE_SCALING (not valid)