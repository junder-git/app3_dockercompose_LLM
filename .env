# .env file - Optimized for 7.5GB VRAM usage on RTX 3060 Ti
SECRET_KEY=your-very-secret-key-change-this-in-production
SECURE_COOKIES=false
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
REDIS_URL=redis://redis:6379/0

# AI Model Configuration - OPTIMIZED for 7.5GB VRAM
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=devstral:24b
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2048               # Increased - you have the VRAM now
MODEL_TIMEOUT=90                    # Slightly longer for larger context

# Rate Limiting - Can be higher with better performance
RATE_LIMIT_MESSAGES_PER_MINUTE=8   # Increased from 5
RATE_LIMIT_LOGIN_ATTEMPTS_PER_MINUTE=5
RATE_LIMIT_API_CALLS_PER_MINUTE=25

# Chat Configuration - Better context with more VRAM
CHAT_CACHE_TTL_SECONDS=7200
CHAT_HISTORY_LIMIT=25               # Increased context
SESSION_LIFETIME_DAYS=7

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_WORKERS=2

# Docker Resource Limits - Optimized for higher VRAM usage
QUART_APP_MEMORY_LIMIT=3G           # Can increase with better performance
QUART_APP_MEMORY_RESERVATION=1G
OLLAMA_MEMORY_LIMIT=24G             # Slightly higher for larger model
OLLAMA_MEMORY_RESERVATION=12G
REDIS_MEMORY_LIMIT=1G

# GPU Configuration - OPTIMIZED for 7.5GB VRAM usage
NVIDIA_VISIBLE_DEVICES=0
CUDA_MEMORY_FRACTION=0.95           # Use almost all VRAM
OLLAMA_GPU_LAYERS=22                # Much higher - target ~7.5GB usage
OLLAMA_NUM_THREAD=8                 # Fewer CPU threads since more on GPU
OLLAMA_LOW_VRAM=0                   # Disable low VRAM mode

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# SSE Configuration - Higher limits with better performance
SSE_HEARTBEAT_INTERVAL=30
SSE_MAX_CONNECTIONS=15              # Increased
SSE_RETRY_TIMEOUT=5000

# Performance Optimizations - HIGH PERFORMANCE mode
OLLAMA_FLASH_ATTENTION=1
OLLAMA_MAIN_GPU=0
OLLAMA_CONTEXT_SIZE=16384           # Doubled context size
OLLAMA_BATCH_SIZE=256               # Larger batches for better throughput
OLLAMA_KEEP_ALIVE=-1                # Permanent keep-alive